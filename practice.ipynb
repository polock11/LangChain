{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_5043/3890438926.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(model = 'llama3.1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a large language model, so I don't have emotions or personal experiences like humans do. I exist solely to provide information and assist with tasks to the best of my abilities.\n",
      "\n",
      "That being said, I'm functioning properly and ready to help with any questions or topics you'd like to discuss! If there's something specific on your mind, feel free to ask. If not, we can explore a wide range of subjects together. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import  ChatOllama\n",
    "\n",
    "model = ChatOllama(model = 'llama3.1')\n",
    "\n",
    "res = model.invoke('what is going on with you?')\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi\n",
      "Hello! How can I help you today? Do you have any questions, need assistance with something, or just want to chat? I'm here to listen and help if I can!\n",
      "You: do you have a memory?\n",
      "I don't have personal memories like humans do. I'm a large language model, my responses are generated based on patterns in the data I was trained on, but I don't have the ability to store or recall specific events or experiences.\n",
      "\n",
      "However, I can keep track of our conversation as we chat! This means that if you ask me something and then come back to it later, I'll be able to pick up where we left off. But this is more like a \"session memory\" rather than a traditional memory.\n",
      "\n",
      "For example, if we had a conversation about a specific topic earlier in our session, and then you asked me a question related to that topic later on, I might be able to recall some of the context from our previous discussion. But this would be based on my understanding of the language patterns and relationships between ideas, rather than any actual memory of what happened previously.\n",
      "\n",
      "Does that make sense?\n",
      "-----History------\n",
      "[SystemMessage(content='You are a helpful assistatn', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! How can I help you today? Do you have any questions, need assistance with something, or just want to chat? I'm here to listen and help if I can!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='do you have a memory?', additional_kwargs={}, response_metadata={}), AIMessage(content='I don\\'t have personal memories like humans do. I\\'m a large language model, my responses are generated based on patterns in the data I was trained on, but I don\\'t have the ability to store or recall specific events or experiences.\\n\\nHowever, I can keep track of our conversation as we chat! This means that if you ask me something and then come back to it later, I\\'ll be able to pick up where we left off. But this is more like a \"session memory\" rather than a traditional memory.\\n\\nFor example, if we had a conversation about a specific topic earlier in our session, and then you asked me a question related to that topic later on, I might be able to recall some of the context from our previous discussion. But this would be based on my understanding of the language patterns and relationships between ideas, rather than any actual memory of what happened previously.\\n\\nDoes that make sense?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "system_msg = SystemMessage(content='You are a helpful assistatn')\n",
    "chat_history.append(system_msg)\n",
    "\n",
    "while True:\n",
    "    query = input('You: ' )\n",
    "    if query == 'exit':\n",
    "        break\n",
    "    \n",
    "    print(f'You: {query}')\n",
    "    chat_history.append(HumanMessage(content=query))\n",
    "\n",
    "    res = model.invoke(chat_history)\n",
    "    print(f\"AI: {res.content}\")\n",
    "    chat_history.append(AIMessage(content=res.content))\n",
    "\n",
    "print('-----History------')\n",
    "print(chat_history)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = 'Tell me about {topic}'\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt_template.invoke({'topic':'Human'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='you are helpful Math teacher', additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about zero', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    ('system', 'you are helpful {system_context}'),\n",
    "    ('human', 'tell me about {topic}')\n",
    "]\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = template.invoke({\n",
    "    'system_context':'Math teacher',\n",
    "    'topic':'zero'\n",
    "})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero! It's a fascinating concept, isn't it? As a math teacher, I'm excited to share with you the rich history and significance of zero.\n",
      "\n",
      "**The Birth of Zero**\n",
      "\n",
      "Zero was not always a part of our number system. In fact, it took centuries for mathematicians to understand its value. The Indian mathematician Aryabhata (476 CE) is credited with using zero as a placeholder in his decimal system. However, the concept of zero didn't become widely accepted until the 7th century, when Indian mathematicians like Brahmagupta and Bhaskara wrote extensively about it.\n",
      "\n",
      "**The Significance of Zero**\n",
      "\n",
      "So, what's so special about zero? Well, my curious student, here are a few reasons why zero is an essential part of our math system:\n",
      "\n",
      "1. **Placeholder**: As I mentioned earlier, zero serves as a placeholder to indicate the absence of a digit in a number.\n",
      "2. **Equality**: Zero equals zero! This simple fact might seem trivial, but it's fundamental to many mathematical operations and proofs.\n",
      "3. **Addition and Subtraction**: Zero is the additive identity (i.e., 0 + x = x), making it an essential component in arithmetic calculations.\n",
      "4. **Multiplication**: Zero multiplied by any number equals zero! This property simplifies many multiplication problems and demonstrates the concept of zero as a \"neutral\" element.\n",
      "\n",
      "**The Cultural Significance of Zero**\n",
      "\n",
      "Zero's impact extends beyond mathematics to culture, philosophy, and science:\n",
      "\n",
      "1. **Indian and Arabic numerals**: The introduction of zero in Indian numerals (0-9) influenced the development of Arabic numerals, which were later adopted by Europeans.\n",
      "2. **Abacus and calculation**: Zero helped create the abacus system, making calculations more efficient and paving the way for modern computing.\n",
      "3. **Mathematical discoveries**: Zero played a crucial role in many significant mathematical breakthroughs, such as algebra and calculus.\n",
      "\n",
      "**A Fun Fact**\n",
      "\n",
      "Did you know that the concept of zero has inspired art and literature? In some cultures, zero is depicted as a dot or a small circle, while others have created intricate designs and symbols to represent this fundamental number!\n",
      "\n",
      "So, my eager learner, I hope this brief excursion into the world of zero has piqued your interest in mathematics and its rich cultural history! Do you have any specific questions about zero?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import  StrOutputParser\n",
    "\n",
    "model = ChatOllama(model = 'llama3.1')\n",
    "\n",
    "messages = [\n",
    "    ('system', 'you are helpful {system_context}'),\n",
    "    ('human', 'tell me about {topic}')\n",
    "]\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(messages=messages)\n",
    "\n",
    "chain = template | model | StrOutputParser()\n",
    "\n",
    "params = {\n",
    "    'system_context':'Math teacher',\n",
    "    'topic':'zero'\n",
    "}\n",
    "\n",
    "res = chain.invoke(params)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
